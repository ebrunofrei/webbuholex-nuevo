// ============================================================================
// ðŸ§  ARGUMENT QUALITY AGGREGATOR â€“ LITISBOT (C1 Â· R2 ENTERPRISE)
// ----------------------------------------------------------------------------
// Integra:
//
//   â€¢ Coherencia lÃ³gica estructural        â†’ scoreCoherence()
//   â€¢ DetecciÃ³n de fallacias               â†’ detectFallacies()
//   â€¢ MÃ©tricas del discurso                â†’ computeArgumentMetrics()
//   â€¢ Perfil cognitivo del jurista         â†’ ajustes finos
//
// NO:
//   âŒ genera texto visible
//   âŒ corrige estilo
//   âŒ reemplaza razonamiento del kernel
//
// Produce evaluaciÃ³n estructural para C2â€“C5.
// ============================================================================

import { scoreCoherence } from "./coherenceScorer.js";
import { detectFallacies } from "./fallacyDetector.js";
import { computeArgumentMetrics } from "./metrics.js";

/* ============================================================================
   CLASSIFICADOR DE RIESGO (C1 INTERNAL)
============================================================================ */

function classifyRisk({ score, fallacies, metrics }) {
  const hasSevereFallacy = fallacies.some((f) => f.severity === "alta");
  const extremeImbalance = metrics.argumentDensity < 0.18;

  if (score < 0.45 || hasSevereFallacy) return "alto";
  if (score < 0.70 || extremeImbalance) return "medio";
  return "bajo";
}

/* ============================================================================
   AGREGADOR PRINCIPAL (C1)
============================================================================ */

export function evaluateArgumentQuality({
  prompt = "",
  cognitiveProfile = {},
}) {
  const text = String(prompt || "").trim();

  // ---------------------------------------------
  // 1ï¸âƒ£ COHERENCIA LÃ“GICA ESTRUCTURAL â€” B1
  // ---------------------------------------------
  const coherence = scoreCoherence({
    prompt: text,
    cognitiveProfile,
  });

  // ---------------------------------------------
  // 2ï¸âƒ£ FALACIAS â€” B2
  // ---------------------------------------------
  const fallacyReport = detectFallacies({
    prompt: text,
    cognitiveProfile,
  });

  const fallacies = fallacyReport.detected ?? [];

  // ---------------------------------------------
  // 3ï¸âƒ£ MÃ‰TRICAS OBJETIVAS â€” B3
  // ---------------------------------------------
  const metrics = computeArgumentMetrics({ texto: text });

  // ---------------------------------------------
  // 4ï¸âƒ£ SCORE INTEGRADO (C1)
  // ---------------------------------------------
  let score = coherence.score ?? 1;

  // PenalizaciÃ³n por falacias (ponderada)
  for (const f of fallacies) {
    if (f.severity === "alta") score -= 0.15;
    else if (f.severity === "media") score -= 0.08;
    else score -= 0.03;
  }

  // Ajuste si el perfil exige rigor extremo
  if (cognitiveProfile?.rigor && fallacies.length) {
    score -= fallacies.length * 0.02;
  }

  // Penalizar baja densidad argumentativa
  if (metrics.argumentDensity < 0.15) {
    score -= 0.05;
  }

  // Rango matemÃ¡tico [0,1]
  score = Math.max(0, Math.min(1, Number(score.toFixed(2))));

  // ---------------------------------------------
  // 5ï¸âƒ£ RISK LEVEL
  // ---------------------------------------------
  const riskLevel = classifyRisk({ score, fallacies, metrics });

  // ---------------------------------------------
  // 6ï¸âƒ£ FLAGS PARA C2â€“C5
  // ---------------------------------------------
  const flags = {
    requiresRevision: score < 0.60,
    highLogicalRisk: riskLevel === "alto",
    hasFallacies: fallacies.length > 0,
    structuralWeakness: metrics.argumentDensity < 0.18,
  };

  // ---------------------------------------------
  // 7ï¸âƒ£ RETORNO CANÃ“NICO
  // ---------------------------------------------
  return {
    score,
    riskLevel,
    coherence,
    fallacies: fallacyReport,
    metrics,
    flags,
  };
}
